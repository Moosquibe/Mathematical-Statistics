{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example of the Expectation-Maximization (EM) algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a sample $Y_1, \\dots, Y_n$ from the mixture density\n",
    "\n",
    "$$ (1-p)\\phi_{\\mu_0, 1}(y) + p\\phi_{\\mu_1,1}(y),$$\n",
    "\n",
    "where $\\phi_{\\mu,\\sigma}(y)$ is the Gaussian density with mean $\\mu$ and variance $\\sigma$, to illustrate the EM algorithm used to find the maximum likelihood estimator of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset\n",
    "\n",
    "We start by generating a dataset consisting of 100 samples with $p=0.3$, $\\mu_0 = 0$ and $\\mu_1 = 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "\n",
    "sample = []\n",
    "cl = [] # To store the class indices\n",
    "\n",
    "p = 0.3\n",
    "mu0 = 0\n",
    "mu1 = 10\n",
    "\n",
    "# There is probably a better way to do this...\n",
    "for i in range(n):\n",
    "    u = np.random.rand();\n",
    "    if (u <= 1-p):\n",
    "        sample.append(np.random.normal(mu0,1));\n",
    "        cl.append(0)\n",
    "    else:\n",
    "        sample.append(np.random.normal(mu1,1));\n",
    "        cl.append(1)\n",
    "        \n",
    "data = pd.DataFrame(list(zip(sample,cl)), columns = ['Sample', 'Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.084045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.478673</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.117113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.335372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.400733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample  Type\n",
       "0  1.084045     0\n",
       "1  1.478673     0\n",
       "2  0.117113     0\n",
       "3  1.335372     0\n",
       "4 -1.400733     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAHfCAYAAABu571YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X2QZeddJ/bv0z3q7tG0ZqzBlmTNBO9iAZJmMF5v0AuQ\nbFuysHaTyJtNVWJIIBjv4he8UNkkyGyyxaSytSCKvHhjK6wXa7wrLeWNhV22KRwMgakUeNF4A8a8\nSNiGLb8JS6y8Hhh5WjNqfvmjT49are6evn17np6e/nyqbvU95zyv5x7N/eqce89tVRUAAPqY2O4B\nAADsJsIXAEBHwhcAQEfCFwBAR8IXAEBHwhcAQEdbEr5aa+9prT3RWvvUGtu/p7X2O8Pj11tr37IV\n/QIA7DRbdebreJLXrrP9j5P8h1X1rUn+YZJ/ukX9AgDsKHu2opGq+vXW2svW2f6byxZ/M8mhregX\nAGCn2Y7PfP3tJB/dhn4BALbdlpz52qjW2quTvCHJd65Txu8dAQA7RlW1Ucp3O/PVWntFkncnuaeq\n/t16Zatq1z1+/Md/fNvHYN7mbd7mbd7mbd6jPTZjK8NXGx4v3NDa1yf5+STfW1V/tIV9AgDsKFty\n2bG19nNJ5pJ8XWvt80l+PMlUkqqqdyf5B0kOJrm/tdaSnKuqW7aibwCAnWSrvu34PRfY/neS/J2t\n6OtyNTc3t91D2BbmvbuY9+5i3rvLbp33ZrTNXq+8WFprdamNCQBgNa211KX6gXsAAIQvAICuhC8A\ngI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICO\nhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQv\nAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCA\njoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6E\nLwCAjoQvAICO9mz3AHayZ599Nk8//XRmZ2dTVeefT05Orlpmaf1q6zbaz8ry641hfn4+Tz75ZK67\n7rr8xV/8xfnnU1NT5+svLzMxMXG+/rlz5/L444/nqquuytTUVP7oj/4oMzMzufrqqzM9PZ0DBw7k\n3LlzefLJJ/OiF70oTzzxRM6ePZskmZmZyUtf+tKcO3fu/FhWjvOpp57KmTNncs011+TMmTNZWFjI\ns88+m6997Ws5cOBA9u/fn/n5+czMzOSrX/1q/vzP/zz79u073/fK/TA/P58/+ZM/yczMzPkyy/fH\nhZ7PzMzk9OnTaa09r+7MzEzm5+fPlz116tQLyozz2i7VWd7uuMfEZl2MNgFYRVVdUo/FIV265ufn\n68EHH6yjR2+v1iZrcnJfJROVXFWTkzOVTNTNN99ab37zm+vmm2+r1iZrauqqam2yDh++qQ4fvqGS\nifPrjh69vR588MGan59ft5/l5R944IF64IEHVh3DxMRUJanWrq6kVbKnkquG7dOVtJqauqZuvvnm\nmpq6Zigzfb7+YvlUsn/Z31bJzPD3wPB3dlmby+u24fl0JYtjmZ6+plqbrImJK1e0sdTmUh/7Krli\nqL/a9tlh3XRdf/031Dvf+c56wxveUJOTB1eUmxnGNFut7RnqtWpt+vy+WBzL0riX+lmay4Fly6lk\n77J9OLVsDhM1Oblv5Nd26fV94IEHhjrLX5+JOnz4pnrggQdGOibW6mfU43kr2gTYTYbcMlrWGbXC\nxX5cyuHrkUceqYMHD9Xs7HdV8sFKzlVSw98PVnJXJS+p5Osq+c41yry6kkOVnDy/bnb2rjp48FCd\nPHlyg/3cPgSNn1qx7b7hjfz24fmhStZq4zuGsX58Rf39lXzLsG2UukvzPzSM6/YhtHzLsO03hm13\nrtHmLZVcObS93r79q/VcuNtbydELjPW2Sq6+QJkXviaL/V071LtjxRw23s7K13bp9d2//yXDvr5j\njbZur/37r93wMbFaP+Mez5tpE2C3Eb4uopMnT9a+fS+u5EPDG9Rqj5PDG/16ZWrY/uKh/HPr9u17\ncb33ve/dQD+rtXFyWP7QiucbbWOpzk9vou5a65eev/cCbY463h+uxaA2ylivXmWsF35Nnqu3mX36\n/Nf25MmTdfLkyZqZOVAbPU5mZg6OdEws9bM1x/NobQLsRtsWvpK8J8kTST61Tpl/nOQzST6Z5JXr\nlLtY+2fT5ufn6+DBQxd4o5qvxbMeF3ozW/4mfWiot7Tu4Wpt3ybaOLWs782O4/pKHt6COaxc/3At\nXk5cq81Rx7vU3laN9UJlPjTsm3H7+lAdPHioXvSil1ZyzUjzHfWYOHjw0LqXCzd2PI/WJsButZnw\ntVXfdjye5LVrbWyt/fUkL6+qb0zypiQ/s0X9dvH+978/Z8/enOSe9UoluVCZ5e5JclOSh5etO5Oq\nV26ijXuX9b2ZcdyQ5GCSM5uou3IOK9efSbLenEYd71J7WzXWC5W5J8nVSb5xzL7uyde+dkNOn55M\n8q0jtDX6MXH27E15+OG157mx43m0NgEYwahpba1HkpdljTNfWQxb/8Wy5UeTXLtG2YsTTcdw9Ojt\ntfiZmPXODmykzMrHB4Z647ZxzbJ6m23jyBbNYeX6C7U5ap9L5bdyrBcqc2SL+vpALV6S3Mx8R+v7\n6NHbxzyeR2sTYLcacktGebTFeuNrrb0syUeq6hWrbPtIkp+oqo8Py7+S5Eer6rdWKVtbNaatsLCw\nkCuumE7VfNa+M8dCkukk65VZzbNJZpI8Myxvto3pJF8b6o3TRttk3aU5TK6yvoZtq7U56n5bKv90\nkn1bONb1ymzFazu5bN3SazW9gTY233drMzl37pkX3DJiY8fzaG0C7GattVRVG6XOJXmfr2PHjp1/\nPjc3l7m5uW0by+nTp3PFFVfm7Nn1dtXpJFdm9N25J8neoX7GaOOKLL5Bj9PG3izec3ecORxYZf3S\n89WMut+Wys+PWO9CY12vzFa8tgeWrVt6rTYSvjbf9549e3P69OkcOPD8eW7seB6tTYDd5MSJEzlx\n4sRYbfQ68/UzSX6tqv7lsPxYkr9WVU+sUtaZL2e+1uDM10b7duYLoI/NnPnayp8XasNjNR9O8n1J\n0lq7LclXVwtel6LJyckcOXJLkl9Yr1SSC5VZzUeGepNjtvHiJB8ds42bxqi7NIfV1t+6Tpujjnep\n/Ee3eKzrlZlMcuMW9fWRLH6x4aMbbGPzr+eRI7esGpI2djyP1iYAo9mS8NVa+7kkH0/yTa21z7fW\n3tBae1Nr7QeTpKp+Mcm/aa19Nsk/SfLWrei3l3vvfWtmZ++/QKm3JrlQmZXuT/JDK9r46U208beW\n9b2Zcbwji7l5K+awcv2F5jRqn0vtbeVYN1LmHWP3NTPzjuzZM5PNzXfjZmfvz9vfvvY8N3Y8j9Ym\nACMY9RP6F/uxOKRLi/t8jTKHlevd52tpnft8AVx+solvO45UuMfjUgxfVe5wv7E5rFzvDvfLX1t3\nuAe4/AhfF9nJkyeH38K7qxbv2bT8t/A+UMlr6rnfdvyONcrM1fN//+8DNTv7muf9ht6F+7mtFn8X\n8L4V25Z+2/G2eu63Hddq49vrwr/tOErdpfkfGtq5rZ777cUPDGUP1eJvGa7W5rfVYqD69gvs21fV\n6r/tuNZYb63nfttxrTIvfE0W+1v6bcdXr5jDxttZ+douvb7P/bbjq9do67bn/bbjhY6J1foZ93je\nTJsAu43w1cH8/Hw99NBDdfTo7dXaZE1OXlnJRCVX1eTkdCUTdfPNt9Zb3vKWOnLktmptsq64YrZa\nm6zDh2+qw4dvqGTi/LqjR2+vhx566AWXdFb2s7z88ePH6/jx46uOobWpSlKtvaiSVsmeIaxMDIGl\n1fT0NXXkyJGamnrJUGb6fP3F8hmeZwgI7Xzd55b3LWtzed1WyeywfnEs09PXVGuTNTGxd9h+YJ02\nrxjaWm37bCUzlUzX9de/vN71rnfVG9/4xpqcPLii3NKYFvfZYr027JvFfbE4lolh294V9ZbGNzXs\ng73L9uHUsjlM1OTklSO/tkuv7/Hjx4c6y1+fiTp8+KY6fvz4SMfEWv2MejxvRZsAu8lmwteW3Wpi\nq1xqt5pYz8LCQk6fPp3Z2dkkOf98+TfClpdZWr/auo32s9qtA9Yaw9mzZ/PlL3851113XZKcfz41\nNXW+/vIyk5OT5+svLCzkS1/6UmZnZ7N379589rOfzfT0dK6++upMTU3lwIEDWVhYyJe//OUcPHgw\nTzzxRM6ePZskmZqayvXXX5+zZ8+eH8vKcX7lK1/J008/nWuvvTZnzpzJwsJCFhYW8vTTT2f//v05\ncOBAzpw5k7179+bUqVP5sz/7s+zbt+983yv3w9mzZ/P4449nZmbmfJnl++NCz/fuXbyHVZLn1d27\nd2/OnDlzvuypU6deUGac13apzvJ2xz0mNutitAlwudvMrSaELwCATdru+3wBAHABwhcAQEfCFwBA\nR8IXAEBHwhcAQEfCFwBAR8IXAEBHwhcAQEfCFwBAR8IXAEBHwhcAQEfCFwBAR8IXAEBHwhcAQEfC\nFwBAR8IXAEBHwhcAQEfCFwBAR8IXAEBHwhcAQEfCFwBAR8IXAEBHwhcAQEfCFwBAR8IXAEBHwhcA\nQEfCFwBAR8IXAEBHwhcAQEfCFwBAR8IXAEBHwhcAQEfCFwBAR8IXAEBHwhcAQEfCFwBAR8IXAEBH\nwhcAQEfCFwBAR8IXAEBHwhcAQEfCFwBAR8IXAEBHwhcAQEfCFwBAR8IXAEBHwhcAQEfCFwBAR8IX\nAEBHwhcAQEdbEr5aa3e31h5rrX26tXbvKtv3t9Y+3Fr7ZGvtd1tr378V/QIA7DStqsZroLWJJJ9O\ncmeSx5N8Isnrq+qxZWV+LMn+qvqx1tqLk/xhkmur6tlV2qtxxwQA0ENrLVXVRqmzFWe+bknymar6\nXFWdS/K+JK9bUaaSXDU8vyrJU6sFLwCAy91WhK9DSb6wbPmLw7rl3pnk5tba40l+J8mPbEG/AAA7\nzp5O/bw2yW9X1R2ttZcn+eXW2iuq6vRqhY8dO3b++dzcXObm5roMEgBgPSdOnMiJEyfGamMrPvN1\nW5JjVXX3sPz2JFVV9y0r8wtJfqKqfmNY/n+S3FtV/3qV9nzmCwDYEbbrM1+fSHJDa+1lrbWpJK9P\n8uEVZT6X5DXDIK9N8k1J/ngL+gYA2FHGvuxYVQuttbcl+VgWw9x7qurR1tqbFjfXu5P8wyTvba19\naqj2o1X1lXH7BgDYaca+7LjVXHYEAHaK7brsCADABglfAAAdCV8AAB0JXwAAHQlfAAAdCV8AAB0J\nXwAAHQlfAAAdCV8AAB0JXwAAHQlfAAAdCV8AAB0JXwAAHQlfAAAdCV8AAB0JXwAAHQlfAAAdCV8A\nAB0JXwAAHQlfAAAdCV8AAB0JXwAAHQlfAAAdCV8AAB0JXwAAHQlfAAAdCV8AAB0JXwAAHQlfAAAd\nCV8AAB0JXwAAHQlfAAAdCV8AAB0JXwAAHQlfAAAdCV8AAB0JXwAAHQlfAAAdCV8AAB0JXwAAHQlf\nAAAdCV8AAB0JXwAAHQlfAAAdCV8AAB0JXwAAHQlfAAAdCV8AAB0JXwAAHQlfAAAdCV8AAB0JXwAA\nHQlfAAAdCV8AAB0JXwAAHW1J+Gqt3d1ae6y19unW2r1rlJlrrf12a+33Wmu/thX9AgDsNK2qxmug\ntYkkn05yZ5LHk3wiyeur6rFlZQ4k+XiS76qqL7XWXlxV/3aN9mrcMQEA9NBaS1W1UepsxZmvW5J8\npqo+V1XnkrwvyetWlPmeJD9fVV9KkrWCFwDA5W4rwtehJF9YtvzFYd1y35TkYGvt11prn2itfe8W\n9AsAsOPs6djPq5LckWRfkn/VWvtXVfXZ1QofO3bs/PO5ubnMzc11GCIAwPpOnDiREydOjNXGVnzm\n67Ykx6rq7mH57Umqqu5bVubeJDNV9T8Nyz+b5KNV9fOrtOczXwDAjrBdn/n6RJIbWmsva61NJXl9\nkg+vKPOhJN/ZWptsrV2Z5NYkj25B3wAAO8rYlx2raqG19rYkH8timHtPVT3aWnvT4uZ6d1U91lr7\npSSfSrKQ5N1V9Qfj9g0AsNOMfdlxq7nsCADsFNt12REAgA0SvgAAOhK+AAA6Er4AADoSvgAAOhK+\nAAA6Er4AADoSvgAAOhK+AAA6Er4AADoSvgAAOhK+AAA6Er4AADoSvgAAOhK+AAA6Er4AADoSvgAA\nOhK+AAA6Er4AADoSvgAAOhK+AAA6Er4AADoSvgAAOhK+AAA6Er4AADoSvgAAOhK+AAA6Er4AADoS\nvgAAOhK+AAA6Er4AADoSvgAAOhK+AAA6Er4AADoSvgAAOhK+AAA6Er4AADoSvgAAOhK+AAA6Er4A\nADoSvgAAOhK+AAA6Er4AADoSvgAAOhK+AAA6Er4AADoSvgAAOhK+AAA6Er4AADoSvgAAOhK+AAA6\nEr4AADoSvgAAOhK+AAA62pLw1Vq7u7X2WGvt0621e9cp922ttXOttb+1Ff0CAOw0Y4ev1tpEkncm\neW2SI0m+u7V24xrlfjLJL43bJwDATrUVZ75uSfKZqvpcVZ1L8r4kr1ul3N9N8nCSJ7egTwCAHWkr\nwtehJF9YtvzFYd15rbXrk/zNqvo/k7Qt6BMAYEfa06mf/z3J8s+CrRvAjh07dv753Nxc5ubmLsqg\nAABGceLEiZw4cWKsNlpVjddAa7clOVZVdw/Lb09SVXXfsjJ/vPQ0yYuTPJ3kB6vqw6u0V+OOCQCg\nh9Zaqmqkq3pbEb4mk/xhkjuT/EmSk0m+u6oeXaP88SQfqaoPrLFd+AIAdoTNhK+xLztW1UJr7W1J\nPpbFz5C9p6oeba29aXFzvXtllXH7BADYqcY+87XVnPkCAHaKzZz5cod7AICOhC8AgI6ELwCAjoQv\nAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCA\njoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6E\nLwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8A\ngI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICO\nhC8AgI6ELwCAjoQvAICOhC8AgI6ELwCAjoQvAICOtiR8tdbubq091lr7dGvt3lW2f09r7XeGx6+3\n1r5lK/oFANhpWlWN10BrE0k+neTOJI8n+USS11fVY8vK3Jbk0ao61Vq7O8mxqrptjfZq3DEBAPTQ\nWktVtVHqbMWZr1uSfKaqPldV55K8L8nrlheoqt+sqlPD4m8mObQF/QIA7DhbEb4OJfnCsuUvZv1w\n9beTfHQL+gUA2HH29OystfbqJG9I8p3rlTt27Nj553Nzc5mbm7uo4wIA2IgTJ07kxIkTY7WxFZ/5\nui2Ln+G6e1h+e5KqqvtWlHtFkp9PcndV/dE67fnMFwCwI2zXZ74+keSG1trLWmtTSV6f5MMrBvb1\nWQxe37te8AIAuNyNfdmxqhZaa29L8rEshrn3VNWjrbU3LW6udyf5B0kOJrm/tdaSnKuqW8btGwBg\npxn7suNWc9kRANgptuuyIwAAGyR8AQB0JHwBAHQkfAEAdCR8AQB0JHwBAHQkfAEAdCR8AQB0JHwB\nAHQkfAEAdCR8AQB0JHwBAHQkfAEAdCR8AQB0JHwBAHQkfAEAdCR8AQB0JHwBAHQkfAEAdCR8AQB0\nJHwBAHQkfAEAdCR8AQB0JHwBAHQkfAEAdCR8AQB0JHwBAHQkfAEAdCR8AQB0JHwBAHQkfAEAdCR8\nAQB0JHwBAHQkfAEAdCR8AQB0JHwBAHQkfAEAdCR8AQB0JHwBAHQkfAEAdCR8AQB0JHwBAHQkfAEA\ndCR8AQB0JHwBAHQkfAEAdCR8AQB0JHwBAHQkfAEAdCR8AQB0JHwBAHQkfAHsEM8++2xOnTqVhYWF\n7R7KBY061uXlNzPPZ599Nk899VSefPLJPPnkk/nKV77yvPor21xafuaZZ/LUU0+9oPzyNpe2La+z\n2vjWGvfKek8//XQ+//nP5+zZsxesv9Z+udA+Wm+sG9m/O+lY25Gq6pJ6LA4JgKqq+fn5evDBB+v2\no0drsrW6amqqJlur248erQcffLDm5+e3e4jnjTrWleX3TU7WRFJXJTUzPF9vnvPz8/XAAw/UjYcO\n1URS08lz9ZNKUi990YvqxkOHarK1mr3iimpJXTM9XRNDmZbU/uHvbFIvP3SofuAHfqC+eWhzakWZ\nA0Mfe1urydbq1ptvrje/+c116803P2/O59ffdFNNtna+rwPDuKaH5WumpuqOO+6oW2688Xz9iaRu\nOHy4bjp8eHGck5N11dDvlRMTa+6jU6dO1YMPPli3DWPZ21pNLOvz5ddfXzcdPrzma7OTjrVLyZBb\nRss6o1a42A/hC2DRI488UocOHqzvmp2tDyZ1Lqka/n4wqbtmZ+vQwYN18uTJ7R7qyGO9YPmkDiX1\nU2vM85FHHqlr9++vbx/Kr6z/6iGgXDm08RtDe3euUf6upF6S1F8d6r0oqZ8d6tw6bPuuNep+x7D9\n48P63xiWv3Odvg4N5T+Y1Lcvq//IsO2OpO4bnq/V7/J9dMeVV9a+1urbpqdfUPa+ITyuta/ump2t\na/fvr5fs378jjrVLjfAFcJk4efJkvXjfvvrQ8Ca41uNDSb14375tfVMcdazvfe97N14+qZMr5nny\n5Mk6ODOzofpXJ7UvqYPD8kb6++mh3nRSPzys22jd945Y/uSy5YNZPEv1oWH9qO2sbLNGbOfqFXUv\nxWPtUrRt4SvJ3UkeS/LpJPeuUeYfJ/lMkk8meeU6bV20HQSwE8zPz9ehgwcv+Ia5/E3x0MGD23JZ\naNSxPpzUvtZGm1tS88Pz66++uq6/+uqR+rtyA+FjZX8PZ/Fs1Ch1H85i0NvM3JaWr0nq1LB+s/to\n6fn8GO1cisfapWoz4WvsD9y31iaSvDPJa5McSfLdrbUbV5T560leXlXfmORNSX5m3H4BLlfvf//7\nc/PZs7lng+XvSXLT2bN5+OGHL+awVjXqWM8keWXVaHNL8vDw/OqvfS0vP316pP7+ylB3lP7mk9yc\n5NAIdc8keeUm+np42fIrktw79L3ZfbT0/P1jtLNumW061i4nW/Ftx1uSfKaqPldV55K8L8nrVpR5\nXZJ/niRV9UiSA621a7egb4DLzv333Ze3nj49Up23nj6dd/3kT16kEa1t1LHen+S/G7GPtyZ519LC\nM8/k750716W/H0kyNUK9sec2LH9w+LvZdpae3z9mO2uW2aZj7XLSFs+YjdFAa/9ZktdW1Q8Oy/9V\nkluq6oeXlflIkp+oqo8Py7+S5Eer6rdWaa/GHRPATrWwsJDpK67IfFX2jFDv2SQzreWZc+cyOTl5\nsYb3PKOOdSHJdBbPKo08tyRfS3LlCPXH7e/pJPuSPJPkQnt03L6W+ngmi3N8Zox2ahhL24LxrFmm\n87F2KWutparaKHVGeU26OXbs2Pnnc3NzmZub27axAPR0+vTpXHnFFdmz4h5QF7Inyd49e3L69Okc\nOHDg4gxuhVHHejqLwWLUN549SfYm+fKI9cftb374ezrJhfbouH0t9TGfxbNt47azN4uXtsZtZ80y\nnY+1S8mJEydy4sSJsdrYijNftyU5VlV3D8tvz+KHz+5bVuZnkvxaVf3LYfmxJH+tqp5YpT1nvoBd\ny5mvF3Lma7R2nPnqazNnvrbiM1+fSHJDa+1lrbWpJK9P8uEVZT6c5PuGQd6W5KurBS+A3W5ycjK3\nHDmSXxix3keS3HLkSNc3w1HHOpnFDwlvam5ZPCN04wj1x+3vF4f+NrJHx+1rqY9fTPKSMdv5SJJb\nt2g8a5bpfKxdbsYOX1W1kORtST6W5PeTvK+qHm2tvam19oNDmV9M8m9aa59N8k8y+mcAAXaNt957\nb+6fnR2pzv2zs/mht7/9Io1obaOO9a1JfnrEPu5P8kNLC9PT+V+vuKJLf+9IMsrF37HnNiz/p8Pf\nzbaz9PytY7azZpltOtYuK6Pem+JiPxaHBLB7uc/X2vewcp+vC+8j9/nqa8gto2WdUStc7IfwBeAO\n9+fLxx3uR9pHcYf73oQvgMvIyZMn69DBg3XX7Gx9IM//vb0PJPWaS+j39kYd6wXLZ/EszH1rzPPk\nyZN17f79dftQfmX9uTz32473ZfF3E5d+M3Gt/l6S1Kvywt92vGXYdtcadZf/NmMNf1+Sxd98XG9u\nHx+Wb19W/+Sw7dV57rcd1+p3+T569fDbjv/+9PQLyi79tuNa++o1y37bcScca5ca4QvgMjM/P18P\nPfRQ3X70aE22VrNXXFGTrdXtR4/WQw89dEld/hl1rCvLXzk5WRND+Jkenq83z/n5+Tp+/HjdeOhQ\nTWTxTNVEUrNJ7U0qSb306qvrxkOHarK12rdnT7WkrpmePl++DcGkDfVuOHSo3vjGN9Y3D21OrSiz\nf+hjJqnJ1urWm2+ut7zlLXXrzTc/b84r188M9Q8M41pq95rp6brzzjvrlptuOl9/IqkbDh+umw4f\nXhzn5GRdNfS7d2JizX106tSpeuihh+q2I0fO9zkxjDlJvfzQobrp8OE1X5uddKxdSjYTvsa+1cRW\nc6sJgNUtLCzk9OnTmZ2dveS/aTbqWJeXTzLyPBcWFnLq1KksLCwkWfwm5oEDB87XXzmepeW9e/fm\n9HCH/uXll7e5tG1pXHv37s2ZM2deML615ry8rzNnzmRqaip/+qd/muuuuy5TU1Pr1l9rv1xoH63s\nc60219q/O+lY226budWE8AUAsEnbdZ8vAAA2SPgCAOhI+AIA6Ej4AgDoSPgCAOhI+AIA6Ej4AgDo\nSPgCAOjp9cKXAAAGdklEQVRI+AIA6Ej4AgDoSPgCAOhI+AIA6Ej4AgDoSPgCAOhI+AIA6Ej4AgDo\nSPgCAOhI+AIA6Ej4AgDoSPgCAOhI+AIA6Ej4AgDoSPgCAOhI+AIA6Ej4AgDoSPgCAOhI+AIA6Ej4\nAgDoSPgCAOhI+AIA6Ej4AgDoSPgCAOhI+AIA6Ej4AgDoSPgCAOhI+AIA6Ej4AgDoSPgCAOhI+AIA\n6Ej4AgDoSPgCAOhI+AIA6Ej4AgDoSPgCAOhI+AIA6Ej4AgDoSPgCAOhI+AIA6Ej4AgDoSPgCAOho\nrPDVWru6tfax1tofttZ+qbV2YJUyh1trv9pa+/3W2u+21n54nD4vVydOnNjuIWwL895dzHt3Me/d\nZbfOezPGPfP19iS/UlXfnORXk/zYKmWeTfL3qupIktuT/FBr7cYx+73s7NaD1rx3F/PeXcx7d9mt\n896MccPX65L8s+H5P0vyN1cWqKovV9Unh+enkzya5NCY/QIA7Ejjhq9rquqJZDFkJblmvcKttb+U\n5JVJHhmzXwCAHalV1foFWvvlJNcuX5WkkvyPSd5bVQeXlX2qqr5ujXZmk5xI8j9X1YfW6W/9AQEA\nXEKqqo1Sfs8GGrxrrW2ttSdaa9dW1ROtteuSPLlGuT1JHk7y4HrBa+hvpAkAAOwk4152/HCS7x+e\n/9dJ1gpWDyT5g6p6x5j9AQDsaBe87Lhu5dYOJvm/kvx7ST6X5D+vqq+21l6a5J9W1X/cWvuOJP9v\nkt/N4uXKSvL3q+r/Hnv0AAA7zFjhCwCA0Vyyd7hvrf23rbW/GM6uXfZaaz/VWnu0tfbJ1trPt9b2\nb/eYLqbW2t2ttcdaa59urd273ePpYbffcLi1NtFa+63W2oe3eyy9tNYOtNbeP/y3/futtVu3e0w9\ntNb+m9ba77XWPtVa+xettantHtPF0Fp7z/DZ508tW3fBm4/vdGvM+7J/D1tt3su2jZRZLsnw1Vo7\nnOSuLF7K3C0+luRIVb0yyWey+g1rLwuttYkk70zy2iRHknz3Lrnx7m6/4fCPJPmD7R5EZ+9I8otV\ndVOSb83ifQ4va62165P83SSvqqpXZPGLXa/f3lFdNMez+O/Ychu5+fhOt9q8d8N72Grz3lRmuSTD\nV5L/Lcl/v92D6KmqfqWq/mJY/M0kh7dzPBfZLUk+U1Wfq6pzSd6XxRv2XtZ28w2Hh3+c/kaSn93u\nsfQy/J//f1BVx5Okqp6tqj/b5mH1Mplk3/BN9yuTPL7N47koqurXk/y7FasvePPxnW61ee+G97A1\nXu9kE5nlkgtfrbV7knyhqn53u8eyjX4gyUe3exAX0aEkX1i2/MXskhCyZBfecHjpH6fd9CHTv5zk\n37bWjg+XW9/dWtu73YO62Krq8ST/S5LPJ/lSkq9W1a9s76i6Gunm45epy/097LzNZpZtCV+ttV8e\nPguw9Pjd4e89Sf5+kh9fXnw7xngxrDPv/2RZmf8hybmq+rltHCoX0XDD4YeT/MhwBuyy1lr7j5I8\nMZz1a7mM/pu+gD1JXpXkXVX1qiRfy+Ilqctaa+1FWTz787Ik1yeZba19z/aOalvtpv/h2FXvYcP/\nTG0qs1zwJqsXw1o3bm2tHU3yl5L8TmutZfG05f/XWrulqla9getOst4Na5Oktfb9Wbw0c0eXAW2f\nLyX5+mXLh4d1l71Rbjh8GfmOJPe01v5Gkr1Jrmqt/fOq+r5tHtfF9sUs/h/xvx6WH06yG75c8pok\nf1xVX0mS1toHknx7ksv+zXiwoZuPX4520XvYkpdnk5nlkrrsWFW/V1XXVdU3VNVfzuI/Xn/lcghe\nF9JauzuLl2Xuqapntns8F9knktzQWnvZ8C2o12fxhr27wa674XBV/f2q+vqq+oYsvta/uguCV4ZL\nT19orX3TsOrO7I4vHHw+yW2ttZnhDenOXN5fNFh5NnejNx/f6Z437130HnZ+3uNklksqfK2isnsu\nUfwfSWaT/PLw+ZD7t3tAF0tVLSR5Wxa/HfP7Sd5XVZfzP85JkuGGw/9lkjtaa789vM53b/e4uKh+\nOMm/aK19MovfdvxH2zyei66qTmbxLN9vJ/mdLP4b/u5tHdRF0lr7uSQfT/JNrbXPt9bekOQnk9zV\nWvvDLAbPn9zOMV4Ma8z7sn8PW2Pey204s7jJKgBAR5f6mS8AgMuK8AUA0JHwBQDQkfAFANCR8AUA\n0JHwBQDQkfAFANDR/w+65jtb/fHWcQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f209ca6dfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "type1_data = data[data.Type == 1]\n",
    "type0_data = data[data.Type == 0]\n",
    "plt.scatter(type1_data.Sample, np.zeros(len(type1_data)), s = 200, c = 'r');\n",
    "plt.scatter(type0_data.Sample, np.ones(len(type0_data)), s = 200, c = 'b');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The iteration rule\n",
    "\n",
    "Now we implement a function carrying out the iterative step using the formulas derived in class. Recall that we first introduced the auxiliary quantity\n",
    "\n",
    "$$\\tau_i^{(j)} = \\frac{p^{(j)}\\phi_{\\mu_1^{(j)},1}(y_i)}{p^{(j)}\\phi_{\\mu_1^{(j)},1}(y_i)+(1-p^{(j)})\\phi_{\\mu_0^{(j)},1}(y_i)}$$\n",
    "\n",
    "in terms of which the update rule takes the form\n",
    "\n",
    "$$p^{(j+1)}=\\frac{1}{n}\\sum_{i=1}^n\\tau_i^{(j)},\\qquad\\mu_0^{(j+1)}=\\frac{\\sum_{i=1}^ny_i(1-\\tau_i^{(j)})}{\\sum_{i=1}^n(1-\\tau_i^{(j)})},\\qquad \\mu_1^{(j+1)}=\\frac{\\sum_{i=1}^ny_i\\tau_i^j}{\\sum_{i=1}^n\\tau_i^j}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tau(p, mu0, mu1, data):\n",
    "    # Computes the tau-factors\n",
    "    a = stats.norm.pdf(data, loc=mu0, scale=1);\n",
    "    b = stats.norm.pdf(data, loc=mu1, scale=1);\n",
    "    \n",
    "    return p * b / (p * b + (1-p) * a)\n",
    "    \n",
    "def update(p_old, mu0_old, mu1_old, y_data):\n",
    "    # Update rule for the iteration\n",
    "    if p_old == 1:\n",
    "        return [1, mu0_old, y_data.mean()]\n",
    "    elif p_old == 0:\n",
    "        return [0, y_data.mean(), mu1_old]\n",
    "    else:\n",
    "        tau_factors = tau(p_old, mu0_old, mu1_old, y_data);\n",
    "        p_new = tau_factors.mean()\n",
    "        mu0_new = np.dot(y_data, 1-tau_factors) / (1-tau_factors).sum()\n",
    "        mu1_new = np.dot(y_data, tau_factors) / tau_factors.sum()\n",
    "        return [p_new, mu0_new, mu1_new]\n",
    "\n",
    "def log_likelihood(p, mu0, mu1, data):\n",
    "    return (np.log((1-p)*stats.norm.pdf(data, loc=mu0, scale=1) + p * stats.norm.pdf(data, loc=mu1, scale=1))).sum();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_theta = [0.1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: [0.1, 0, 1] log-Likelihood: -1328.53\n",
      " 1. p: 0.36, mu0: -0.16, mu1: 8.10   log-Likelihood: -255.98 \n",
      " 2. p: 0.29, mu0: -0.05, mu1: 9.74   log-Likelihood: -215.69 \n",
      " 3. p: 0.29, mu0: -0.05, mu1: 9.74   log-Likelihood: -215.69 \n",
      " 4. p: 0.29, mu0: -0.05, mu1: 9.74   log-Likelihood: -215.69 \n",
      " 5. p: 0.29, mu0: -0.05, mu1: 9.74   log-Likelihood: -215.69 \n",
      " 6. p: 0.29, mu0: -0.05, mu1: 9.74   log-Likelihood: -215.69 \n",
      " 7. p: 0.29, mu0: -0.05, mu1: 9.74   log-Likelihood: -215.69 \n",
      " 8. p: 0.29, mu0: -0.05, mu1: 9.74   log-Likelihood: -215.69 \n",
      " 9. p: 0.29, mu0: -0.05, mu1: 9.74   log-Likelihood: -215.69 \n",
      "10. p: 0.29, mu0: -0.05, mu1: 9.74   log-Likelihood: -215.69 \n",
      "11. p: 0.29, mu0: -0.05, mu1: 9.74   log-Likelihood: -215.69 \n",
      "12. p: 0.29, mu0: -0.05, mu1: 9.74   log-Likelihood: -215.69 \n",
      "13. p: 0.29, mu0: -0.05, mu1: 9.74   log-Likelihood: -215.69 \n",
      "14. p: 0.29, mu0: -0.05, mu1: 9.74   log-Likelihood: -215.69 \n",
      "15. p: 0.29, mu0: -0.05, mu1: 9.74   log-Likelihood: -215.69 \n"
     ]
    }
   ],
   "source": [
    "num_of_iter = 15\n",
    "\n",
    "theta = initial_theta\n",
    "ll = log_likelihood(theta[0], theta[1], theta[2], data.Sample)\n",
    "print(\"Initial: {} log-Likelihood: {:.2f}\".format(theta, ll))\n",
    "\n",
    "for i in range(num_of_iter):\n",
    "    theta = update(theta[0], theta[1], theta[2], data.Sample)\n",
    "    ll = log_likelihood(theta[0], theta[1], theta[2], data.Sample)\n",
    "    print(\"{:2d}. p: {:.2f}, mu0: {:.2f}, mu1: {:.2f}   log-Likelihood: {:.2f} \".format(i+1,theta[0],theta[1],theta[2], ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the algorithm converges pretty quickly. We coul tweak this implementation by stopping the iteration, when the log-likelihood is not increasing anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-separable data\n",
    "\n",
    "The above situation worked well because the two components of the mixture were well separated. Let us look at the case of non-separable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "\n",
    "sample = []\n",
    "cl = []\n",
    "\n",
    "p = 0.3\n",
    "mu0 = 0\n",
    "mu1 = 2\n",
    "\n",
    "# There is probably a better way to do this...\n",
    "for i in range(n):\n",
    "    u = np.random.rand();\n",
    "    if (u <= 1-p):\n",
    "        sample.append(np.random.normal(mu0,1));\n",
    "        cl.append(0)\n",
    "    else:\n",
    "        sample.append(np.random.normal(mu1,1));\n",
    "        cl.append(1)\n",
    "        \n",
    "data = pd.DataFrame(list(zip(sample,cl)), columns = ['Sample', 'Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAHfCAYAAABnDB0iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2093a43198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "type1_data = data[data.Type == 1]\n",
    "type0_data = data[data.Type == 0]\n",
    "plt.scatter(type1_data.Sample, np.zeros(len(type1_data)), s = 200, c = 'r');\n",
    "plt.scatter(type0_data.Sample, np.ones(len(type0_data)), s = 200, c = 'b');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: [0.1, -1, 1] log-Likelihood: -238.74\n",
      " 1. p: 0.35, mu0: 0.01, mu1: 1.80   log-Likelihood: -171.58 \n",
      " 2. p: 0.32, mu0: 0.06, mu1: 1.85   log-Likelihood: -171.01 \n",
      " 3. p: 0.30, mu0: 0.09, mu1: 1.92   log-Likelihood: -170.47 \n",
      " 4. p: 0.27, mu0: 0.12, mu1: 2.02   log-Likelihood: -169.91 \n",
      " 5. p: 0.25, mu0: 0.14, mu1: 2.12   log-Likelihood: -169.34 \n",
      " 6. p: 0.23, mu0: 0.17, mu1: 2.23   log-Likelihood: -168.77 \n",
      " 7. p: 0.21, mu0: 0.19, mu1: 2.34   log-Likelihood: -168.22 \n",
      " 8. p: 0.19, mu0: 0.21, mu1: 2.46   log-Likelihood: -167.72 \n",
      " 9. p: 0.17, mu0: 0.23, mu1: 2.58   log-Likelihood: -167.27 \n",
      "10. p: 0.16, mu0: 0.25, mu1: 2.70   log-Likelihood: -166.90 \n",
      "11. p: 0.14, mu0: 0.27, mu1: 2.81   log-Likelihood: -166.61 \n",
      "12. p: 0.13, mu0: 0.29, mu1: 2.90   log-Likelihood: -166.39 \n",
      "13. p: 0.12, mu0: 0.30, mu1: 2.99   log-Likelihood: -166.25 \n",
      "14. p: 0.12, mu0: 0.31, mu1: 3.05   log-Likelihood: -166.15 \n",
      "15. p: 0.11, mu0: 0.32, mu1: 3.11   log-Likelihood: -166.10 \n",
      "16. p: 0.11, mu0: 0.33, mu1: 3.15   log-Likelihood: -166.06 \n",
      "17. p: 0.11, mu0: 0.33, mu1: 3.19   log-Likelihood: -166.04 \n",
      "18. p: 0.10, mu0: 0.33, mu1: 3.21   log-Likelihood: -166.03 \n",
      "19. p: 0.10, mu0: 0.34, mu1: 3.23   log-Likelihood: -166.02 \n",
      "20. p: 0.10, mu0: 0.34, mu1: 3.24   log-Likelihood: -166.02 \n",
      "21. p: 0.10, mu0: 0.34, mu1: 3.26   log-Likelihood: -166.02 \n",
      "22. p: 0.10, mu0: 0.34, mu1: 3.26   log-Likelihood: -166.01 \n",
      "23. p: 0.10, mu0: 0.34, mu1: 3.27   log-Likelihood: -166.01 \n",
      "24. p: 0.10, mu0: 0.34, mu1: 3.27   log-Likelihood: -166.01 \n",
      "25. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n",
      "26. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n",
      "27. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n",
      "28. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n",
      "29. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n",
      "30. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n"
     ]
    }
   ],
   "source": [
    "initial_theta = [0.1, -1, 1]\n",
    "\n",
    "num_of_iter = 30\n",
    "\n",
    "theta = initial_theta\n",
    "ll = log_likelihood(theta[0], theta[1], theta[2], data.Sample)\n",
    "print(\"Initial: {} log-Likelihood: {:.2f}\".format(theta, ll))\n",
    "\n",
    "for i in range(num_of_iter):\n",
    "    theta = update(theta[0], theta[1], theta[2], data.Sample)\n",
    "    ll = log_likelihood(theta[0], theta[1], theta[2], data.Sample)\n",
    "    print(\"{:2d}. p: {:.2f}, mu0: {:.2f}, mu1: {:.2f}   log-Likelihood: {:.2f} \".format(i+1,theta[0],theta[1],theta[2], ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that while the log likelihood is increasing on every step as it should. The parameter values are not getting close to the real one. In general, we cannot guarrantee that we will find the global maximum of the likelihood function, we can get stuck in a local maximum as well and therefore a lot depends on initialization. Also note that our estimator itself is random so we are also limited by the finite sample size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: [0.3, 0, 2] log-Likelihood: -170.81\n",
      " 1. p: 0.28, mu0: 0.10, mu1: 2.03   log-Likelihood: -169.97 \n",
      " 2. p: 0.25, mu0: 0.14, mu1: 2.12   log-Likelihood: -169.39 \n",
      " 3. p: 0.23, mu0: 0.16, mu1: 2.22   log-Likelihood: -168.82 \n",
      " 4. p: 0.21, mu0: 0.19, mu1: 2.33   log-Likelihood: -168.27 \n",
      " 5. p: 0.19, mu0: 0.21, mu1: 2.45   log-Likelihood: -167.76 \n",
      " 6. p: 0.17, mu0: 0.23, mu1: 2.57   log-Likelihood: -167.30 \n",
      " 7. p: 0.16, mu0: 0.25, mu1: 2.69   log-Likelihood: -166.92 \n",
      " 8. p: 0.14, mu0: 0.27, mu1: 2.80   log-Likelihood: -166.63 \n",
      " 9. p: 0.13, mu0: 0.28, mu1: 2.89   log-Likelihood: -166.41 \n",
      "10. p: 0.13, mu0: 0.30, mu1: 2.98   log-Likelihood: -166.26 \n",
      "11. p: 0.12, mu0: 0.31, mu1: 3.05   log-Likelihood: -166.16 \n",
      "12. p: 0.11, mu0: 0.32, mu1: 3.11   log-Likelihood: -166.10 \n",
      "13. p: 0.11, mu0: 0.32, mu1: 3.15   log-Likelihood: -166.06 \n",
      "14. p: 0.11, mu0: 0.33, mu1: 3.18   log-Likelihood: -166.04 \n",
      "15. p: 0.10, mu0: 0.33, mu1: 3.21   log-Likelihood: -166.03 \n",
      "16. p: 0.10, mu0: 0.34, mu1: 3.23   log-Likelihood: -166.02 \n",
      "17. p: 0.10, mu0: 0.34, mu1: 3.24   log-Likelihood: -166.02 \n",
      "18. p: 0.10, mu0: 0.34, mu1: 3.25   log-Likelihood: -166.02 \n",
      "19. p: 0.10, mu0: 0.34, mu1: 3.26   log-Likelihood: -166.01 \n",
      "20. p: 0.10, mu0: 0.34, mu1: 3.27   log-Likelihood: -166.01 \n",
      "21. p: 0.10, mu0: 0.34, mu1: 3.27   log-Likelihood: -166.01 \n",
      "22. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n",
      "23. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n",
      "24. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n",
      "25. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n",
      "26. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n",
      "27. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n",
      "28. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n",
      "29. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n",
      "30. p: 0.10, mu0: 0.35, mu1: 3.28   log-Likelihood: -166.01 \n"
     ]
    }
   ],
   "source": [
    "initial_theta = [0.3, 0, 2]\n",
    "\n",
    "num_of_iter = 30\n",
    "\n",
    "theta = initial_theta\n",
    "ll = log_likelihood(theta[0], theta[1], theta[2], data.Sample)\n",
    "print(\"Initial: {} log-Likelihood: {:.2f}\".format(theta, ll))\n",
    "\n",
    "for i in range(num_of_iter):\n",
    "    theta = update(theta[0], theta[1], theta[2], data.Sample)\n",
    "    ll = log_likelihood(theta[0], theta[1], theta[2], data.Sample)\n",
    "    print(\"{:2d}. p: {:.2f}, mu0: {:.2f}, mu1: {:.2f}   log-Likelihood: {:.2f} \".format(i+1,theta[0],theta[1],theta[2], ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try this on a much larger dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "\n",
    "sample = []\n",
    "cl = []\n",
    "\n",
    "p = 0.3\n",
    "mu0 = 0\n",
    "mu1 = 2\n",
    "\n",
    "# There is probably a better way to do this...\n",
    "for i in range(n):\n",
    "    u = np.random.rand();\n",
    "    if (u <= 1-p):\n",
    "        sample.append(np.random.normal(mu0,1));\n",
    "        cl.append(0)\n",
    "    else:\n",
    "        sample.append(np.random.normal(mu1,1));\n",
    "        cl.append(1)\n",
    "        \n",
    "data = pd.DataFrame(list(zip(sample,cl)), columns = ['Sample', 'Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: [0.3, 0, 2] log-Likelihood: -1667.82\n",
      " 1. p: 0.29, mu0: 0.05, mu1: 1.91   log-Likelihood: -1665.36 \n",
      " 2. p: 0.29, mu0: 0.06, mu1: 1.89   log-Likelihood: -1665.15 \n",
      " 3. p: 0.29, mu0: 0.06, mu1: 1.88   log-Likelihood: -1665.12 \n",
      " 4. p: 0.29, mu0: 0.07, mu1: 1.88   log-Likelihood: -1665.12 \n",
      " 5. p: 0.29, mu0: 0.07, mu1: 1.88   log-Likelihood: -1665.12 \n",
      " 6. p: 0.29, mu0: 0.07, mu1: 1.88   log-Likelihood: -1665.12 \n",
      " 7. p: 0.29, mu0: 0.07, mu1: 1.88   log-Likelihood: -1665.12 \n",
      " 8. p: 0.29, mu0: 0.07, mu1: 1.88   log-Likelihood: -1665.12 \n",
      " 9. p: 0.29, mu0: 0.07, mu1: 1.88   log-Likelihood: -1665.12 \n",
      "10. p: 0.29, mu0: 0.07, mu1: 1.88   log-Likelihood: -1665.12 \n",
      "11. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "12. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "13. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "14. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "15. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "16. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "17. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "18. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "19. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "20. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "21. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "22. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "23. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "24. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "25. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "26. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "27. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "28. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "29. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n",
      "30. p: 0.29, mu0: 0.07, mu1: 1.89   log-Likelihood: -1665.12 \n"
     ]
    }
   ],
   "source": [
    "initial_theta = [0.3, 0, 2]\n",
    "\n",
    "num_of_iter = 30\n",
    "\n",
    "theta = initial_theta\n",
    "ll = log_likelihood(theta[0], theta[1], theta[2], data.Sample)\n",
    "print(\"Initial: {} log-Likelihood: {:.2f}\".format(theta, ll))\n",
    "\n",
    "for i in range(num_of_iter):\n",
    "    theta = update(theta[0], theta[1], theta[2], data.Sample)\n",
    "    ll = log_likelihood(theta[0], theta[1], theta[2], data.Sample)\n",
    "    print(\"{:2d}. p: {:.2f}, mu0: {:.2f}, mu1: {:.2f}   log-Likelihood: {:.2f} \".format(i+1,theta[0],theta[1],theta[2], ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. Also note that the convergence is also much faster. Here is one more with the off initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: [0.1, -1, 1] log-Likelihood: -2296.02\n",
      " 1. p: 0.36, mu0: -0.07, mu1: 1.74   log-Likelihood: -1667.12 \n",
      " 2. p: 0.36, mu0: -0.04, mu1: 1.72   log-Likelihood: -1666.44 \n",
      " 3. p: 0.35, mu0: -0.02, mu1: 1.72   log-Likelihood: -1666.24 \n",
      " 4. p: 0.35, mu0: -0.01, mu1: 1.73   log-Likelihood: -1666.10 \n",
      " 5. p: 0.34, mu0: -0.01, mu1: 1.73   log-Likelihood: -1665.99 \n",
      " 6. p: 0.34, mu0: -0.00, mu1: 1.74   log-Likelihood: -1665.89 \n",
      " 7. p: 0.34, mu0: 0.00, mu1: 1.75   log-Likelihood: -1665.80 \n",
      " 8. p: 0.33, mu0: 0.01, mu1: 1.76   log-Likelihood: -1665.72 \n",
      " 9. p: 0.33, mu0: 0.01, mu1: 1.77   log-Likelihood: -1665.65 \n",
      "10. p: 0.33, mu0: 0.02, mu1: 1.78   log-Likelihood: -1665.59 \n",
      "11. p: 0.33, mu0: 0.02, mu1: 1.78   log-Likelihood: -1665.53 \n",
      "12. p: 0.32, mu0: 0.02, mu1: 1.79   log-Likelihood: -1665.48 \n",
      "13. p: 0.32, mu0: 0.03, mu1: 1.80   log-Likelihood: -1665.44 \n",
      "14. p: 0.32, mu0: 0.03, mu1: 1.80   log-Likelihood: -1665.40 \n",
      "15. p: 0.32, mu0: 0.03, mu1: 1.81   log-Likelihood: -1665.37 \n",
      "16. p: 0.31, mu0: 0.03, mu1: 1.81   log-Likelihood: -1665.34 \n",
      "17. p: 0.31, mu0: 0.04, mu1: 1.82   log-Likelihood: -1665.31 \n",
      "18. p: 0.31, mu0: 0.04, mu1: 1.82   log-Likelihood: -1665.29 \n",
      "19. p: 0.31, mu0: 0.04, mu1: 1.83   log-Likelihood: -1665.27 \n",
      "20. p: 0.31, mu0: 0.04, mu1: 1.83   log-Likelihood: -1665.25 \n",
      "21. p: 0.31, mu0: 0.04, mu1: 1.83   log-Likelihood: -1665.23 \n",
      "22. p: 0.30, mu0: 0.05, mu1: 1.84   log-Likelihood: -1665.22 \n",
      "23. p: 0.30, mu0: 0.05, mu1: 1.84   log-Likelihood: -1665.20 \n",
      "24. p: 0.30, mu0: 0.05, mu1: 1.85   log-Likelihood: -1665.19 \n",
      "25. p: 0.30, mu0: 0.05, mu1: 1.85   log-Likelihood: -1665.18 \n",
      "26. p: 0.30, mu0: 0.05, mu1: 1.85   log-Likelihood: -1665.18 \n",
      "27. p: 0.30, mu0: 0.05, mu1: 1.85   log-Likelihood: -1665.17 \n",
      "28. p: 0.30, mu0: 0.06, mu1: 1.86   log-Likelihood: -1665.16 \n",
      "29. p: 0.30, mu0: 0.06, mu1: 1.86   log-Likelihood: -1665.16 \n",
      "30. p: 0.30, mu0: 0.06, mu1: 1.86   log-Likelihood: -1665.15 \n"
     ]
    }
   ],
   "source": [
    "initial_theta = [0.1, -1, 1]\n",
    "\n",
    "num_of_iter = 30\n",
    "\n",
    "theta = initial_theta\n",
    "ll = log_likelihood(theta[0], theta[1], theta[2], data.Sample)\n",
    "print(\"Initial: {} log-Likelihood: {:.2f}\".format(theta, ll))\n",
    "\n",
    "for i in range(num_of_iter):\n",
    "    theta = update(theta[0], theta[1], theta[2], data.Sample)\n",
    "    ll = log_likelihood(theta[0], theta[1], theta[2], data.Sample)\n",
    "    print(\"{:2d}. p: {:.2f}, mu0: {:.2f}, mu1: {:.2f}   log-Likelihood: {:.2f} \".format(i+1,theta[0],theta[1],theta[2], ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good! Feel free to play around and get a feel for how the algorithm behaves with different initialization, sample sizes, and parameters."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
