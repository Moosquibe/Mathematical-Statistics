# Mathematical Statistics

This is the GitHub repository for the class Math-UA 234 Mathematical Statistics course given by Dr. Zsolt Pajor-Gyulai at the Courant Institute of Mathematics, New York University in the spring semester of 2018. The schedule below is tentative and is subject to change during the course of the semester.

Project sign up form [here](https://goo.gl/forms/MQZ4LeL0Ie2LuYPF2).

W: Wassermann, CB: Casella Berger

| Lecture | Date | Description | Notebooks used | Reading | Remark |
| --- | --- | --- | --- | --- | --- |
| `Lecture 1`    | 1/23 | Probability Spaces, Distributions (Review) | [Python Fundamentals](https://github.com/Moosquibe/Mathematical-Statistics/blob/master/Notebooks/Python_Fundamentals.ipynb), [Numpy Basics](https://github.com/Moosquibe/Mathematical-Statistics/blob/master/Notebooks/Numpy_Basics.ipynb), [Pandas_Basics](https://github.com/Moosquibe/Mathematical-Statistics/blob/master/Notebooks/Pandas_Basics.ipynb) | W 1-5, CB 1-4 | HW 1 Assigned, CHW1 Assigned | 
| `Lecture 2`    | 1/25 | Conditional Expectation, Sample mean and variance, Special distributions (Review)  | [Special Distributions](https://github.com/Moosquibe/Mathematical-Statistics/blob/master/Notebooks/SpecialDistr.ipynb) | W 1-5, CB 1-5 
| No recitation | 1/26 |  | | | |
| `Lecture 3`    | 1/30 | Basic statistical concepts  |  | W 6 | |
| `Lecture 4`    | 2/1 | Estimation of the CDF and its functionals, nonparametric bootsrap | [Empirical CDF](https://github.com/Moosquibe/Mathematical-Statistics/blob/master/Notebooks/Empirical_CDF.ipynb), [Cloud Seeding](https://github.com/Moosquibe/Mathematical-Statistics/blob/master/Notebooks/cloud_seeding.ipynb) | W 7-8, | HW2 Assigned, CHW2 Assigned| 
| `Recitation 1` | 2/2 | Empirical distribution example and bootstrapping | [Recitation_1_FINAL](https://github.com/Moosquibe/Mathematical-Statistics/blob/master/Notebooks/Recitation_1_FINAL.ipynb "Recitation 1")|  | HW1 Due | 
| `Lecture 5`    | 2/6 | Sufficient, Ancilliary, and Complete statistics | | W 9.13.2, CB 6.2| |
| `Lecture 6`    | 2/8 | Method of moments, Maximum likelihood estimators | | W 9.2, 9.3, 9.4, CB 7.2.1, 7.2.2| HW3 Assigned |
| `Recitation 2` | 2/9 | Exponential families | [Recitation_2_FINAL](https://github.com/Moosquibe/Mathematical-Statistics/blob/master/Notebooks/Recitation_2_FINAL.ipynb "Recitation 2")| W 9.13.3, CB 3.4 | CHW1 Due, HW2 Due |
| `Lecture 7`    | 2/13| Invariance of MLE, Computation of MLE, Bayes estimators | [EM Algorithm](https://github.com/Moosquibe/Mathematical-Statistics/blob/master/Notebooks/EM_algorithm.ipynb) | W 9.6, 11.1, 11.2, CB 7.2.2, 7.2.3, 7.2.4 | |
| `Lecture 8`    | 2/15| More on Bayesian estimation| | W 11.3, 11.6, 11.9 | CHW3 Assigned, HW4 Assigned |
| `Recitation 3` | 2/16| Prior and posterior distributions | [Recitation_3_FINAL](https://github.com/Moosquibe/Mathematical-Statistics/blob/master/Notebooks/Recitation_3_FINAL.ipynb "Recitation 3")| | HW 3 Due, CHW2 Due |
| `Lecture 9`    | 2/20| Best unbiased estimators, Cramer-Rao inequality | | CB 7.3.2 ||
| `Lecture 10`   | 2/22| Attainment of the Cramer-Rao bound, Sufficiency and unbiasedness | | CB 7.3.3 | HW5 Assigned|
| `Recitation 4` | 2/23| Cramer-Rao inequality, Rao-Blackwell theorem |[Recitation_4_FINAL](https://github.com/Moosquibe/Mathematical-Statistics/blob/master/Notebooks/Recitation_4_FINAL.ipynb "Recitation 4")|| HW4 Due|
| `Lecture 11`   | 2/27| Statistical decision theory, loss functions, risk functions|| CB 7.3.4, W 12.1-12.3 ||
| `Lecture 12`   | 3/1 | Consistency of point estimators, CLT (Review), the delta method | [LLN_CLT](https://github.com/Moosquibe/Mathematical-Statistics/blob/master/Notebooks/LLN_CLT.ipynb) |CB 10.1.1, 5.5.3, 5.5.4, W 9.5, 9.9-9.10 | HW6 Assigned|
| `Recitation 5` | 3/2 | Loss functions and risk |[Recitation_5_FINAL](https://github.com/Moosquibe/Mathematical-Statistics/blob/master/Notebooks/Recitation_5_FINAL.ipynb "Recitation 5")|  CB 7.61 7.65 and W9.14.4 Example data sources| HW5 Due|
| `Lecture 13`   | 3/6 | Asymptotic normality and efficiency of point estimators, parametric bootstrap ||CB 10.1.2-10.1.4, W 9.7, 9.8, 9.11| |
| `Lecture 14`   | 3/8 | Hypothesis testing basics, Likelihood ratio test || CB 8.1, 8.2.1, W 10.6| HW7 Assigned, CHW4 Assigned Term project proposals due|
| `Recitation 6` | 3/9 | ||| HW6 Due, CHW3 Due |
| Spring Break   | 3/13| ||| |
| Spring Break   | 3/15| ||| |
| Spring Break   | 3/16| ||| |
| `Lecture 15`   | 3/20| Asymptotic distribution of LRT, Bayesian testing || CB 8.2.2, W 11.8 | |
| `Lecture 16`   | 3/22| p-values, multiple testing ||CB 8.3.4, W 10.2| HW8 Assigned |
| `Recitation 7` | 3/23| ||| HW 7 Due |
| `Lecture 17`   | 3/27| Midterm Review ||| |
|    MIDTERM     | 3/29| ||| |
| `Recitation 8` | 3/30| Solutions to Midterm ||| |
| `Lecture 18`   | 4/3 |  Power functions, sizes, levels | | CB 8.3.1| |
| `Lecture 19`   | 4/5 |  Most powerful tests, Neyman-Pearson lemma || CB 8.3.2| HW9 Assigned|
| `Recitation 9` | 4/6 | ||| HW8 Due|
| `Lecture 20`   | 4/10| Wald test, Chi-squared test, Permutation test, Goodness of Fit test || CB 10.3.2, W 10.1, 10.4, 10.5, 10.8 ||
| `Lecture 21`   | 4/12| Interval estimation, inverting tests, pivoting ||CB 9.1, 9.2.1, 9.2.2 | HW10 Assigned|
| `Recitation 10`| 4/13| ||| HW9 Due |
| `Lecture 22`   | 4/17| CDF as a pivot, Bayesian interval, Optimal CI size for unimodal distributions || CB 9.2.3, 9.2.4, 9.3.1| |
| `Lecture 23`   | 4/19| Loss functions in hypothesis testing and interval estimations, Large Sample approximate intervals || CB 8.3.5, 9.3.4, 10.4.1, 10.4.2 | CHW5 Assigned, HW11 Assigned|
| `Recitation 11`| 4/20| ||| HW10 Due, CHW4 Due|
| `Lecture 24`   | 4/24| Simple linear regression || CB 11.3.1-11.3.4 W 13.1, 13.2 | |
| `Lecture 25`   | 4/26| Estimation and prediction with simple linear regression. ||W 13.4| HW 12 Assigned|
| `Recitation 12`| 4/27| ||| HW11 Due |
| `Lecture 26`   | 5/1 | Logistic regression, Multiple regression || W 13.5, 13.7 CB 12.3 | |
| `Lecture 27`   | 5/3 | Final Review ||| |
| `In Class Final`| 5/4 | ||| HW12 Due, CHW5 Due |
| Holiday!!! | 5/8 | ||| Term project Due


